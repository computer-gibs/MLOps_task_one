Started by user admin
[Pipeline] Start of Pipeline
[Pipeline] node
Running on Jenkins in /var/lib/jenkins/workspace/MLOps_task_two
[Pipeline] {
[Pipeline] stage
[Pipeline] { (Get github repo)
[Pipeline] git
The recommended git tool is: NONE
No credentials specified
 > git rev-parse --resolve-git-dir /var/lib/jenkins/workspace/MLOps_task_two/.git # timeout=10
Fetching changes from the remote Git repository
 > git config remote.origin.url https://github.com/computer-gibs/MLOps_task_one.git # timeout=10
Fetching upstream changes from https://github.com/computer-gibs/MLOps_task_one.git
 > git --version # timeout=10
 > git --version # 'git version 2.34.1'
 > git fetch --tags --force --progress -- https://github.com/computer-gibs/MLOps_task_one.git +refs/heads/*:refs/remotes/origin/* # timeout=10
 > git rev-parse refs/remotes/origin/main^{commit} # timeout=10
Checking out Revision b67c08a3556bcc951932c6514815850cd3e725a6 (refs/remotes/origin/main)
 > git config core.sparsecheckout # timeout=10
 > git checkout -f b67c08a3556bcc951932c6514815850cd3e725a6 # timeout=10
 > git branch -a -v --no-abbrev # timeout=10
 > git branch -D main # timeout=10
 > git checkout -b main b67c08a3556bcc951932c6514815850cd3e725a6 # timeout=10
Commit message: "Update docker-compose.yml"
 > git rev-list --no-walk b67c08a3556bcc951932c6514815850cd3e725a6 # timeout=10
[Pipeline] }
[Pipeline] // stage
[Pipeline] stage
[Pipeline] { (Build docker file)
[Pipeline] sh
+ docker-compose -f lab3/docker-compose.yml build
Building model-api
#1 [internal] load .dockerignore
#1 transferring context:
#1 transferring context: 2B done
#1 DONE 0.0s

#2 [internal] load build definition from Dockerfile
#2 transferring dockerfile: 237B 0.0s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.10
#3 DONE 0.6s

#4 [1/6] FROM docker.io/library/python:3.10@sha256:5a71ab8ffc96d7ac9cbe32aff7878371242d36a3038a266941ccdb5c83cc5dd5
#4 DONE 0.0s

#5 [internal] load build context
#5 transferring context: 226B 0.0s done
#5 DONE 0.0s

#6 [3/6] COPY requirements.txt ./requirements.txt
#6 CACHED

#7 [2/6] WORKDIR /app
#7 CACHED

#8 [5/6] COPY . .
#8 CACHED

#9 [4/6] RUN pip3 install -r requirements.txt
#9 CACHED

#10 [6/6] RUN chmod +x ./model_training.py
#10 CACHED

#11 exporting to image
#11 exporting layers done
#11 writing image sha256:4ccdd255aabc5e7bb86262687fc548aec66d92ac6496717ea18a263a3c0f5a86 done
#11 naming to docker.io/library/mytagforlab done
#11 DONE 0.0s
[Pipeline] }
[Pipeline] // stage
[Pipeline] stage
[Pipeline] { (Run docker image)
[Pipeline] sh
+ docker-compose -f lab3/docker-compose.yml up
Creating network "lab3_default" with the default driver
Creating lab3_model-api_1 ... 
Creating lab3_model-api_1 ... done
Attaching to lab3_model-api_1
[36mmodel-api_1  |[0m Train data:
[36mmodel-api_1  |[0m dataset2_processed.csv - MSE: 1.0007321423003708
[36mmodel-api_1  |[0m dataset1_processed.csv - MSE: 0.9991525660122104
[36mmodel-api_1  |[0m Test data:
[36mmodel-api_1  |[0m dataset3_processed.csv - MSE: 0.999891500096275
[36mlab3_model-api_1 exited with code 0
[0m
[Pipeline] }
[Pipeline] // stage
[Pipeline] }
[Pipeline] // node
[Pipeline] End of Pipeline
Finished: SUCCESS
